from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess
import os

model_dir = "/home/niwang/models/SenseVoiceSmall"

# åˆå§‹åŒ–æ¨¡å‹
model = AutoModel(
    model=model_dir,
    vad_model="fsmn-vad",
    vad_kwargs={"max_single_segment_time": 30000},
    device="cuda:0",
    hub="hf",
)

# å‡†å¤‡å¤šä¸ªéŸ³é¢‘æ–‡ä»¶è·¯å¾„
audio_files = [
    "data/æ‚²ä¼¤.mp3",
    "data/æ‚²ä¼¤2.mp3",
    "data/æ‚²ä¼¤3.mp3"
    # æ·»åŠ æ›´å¤šéŸ³é¢‘æ–‡ä»¶è·¯å¾„
    # "/path/to/audio2.mp3",
    # "/path/to/audio3.mp3",
]

# æ‰¹é‡æ¨ç†
results = model.generate(
    input=audio_files,  # ç›´æ¥ä¼ å…¥æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    cache={},
    language="auto",  # "zn", "en", "yue", "ja", "ko", "nospeech"
    use_itn=True,
    batch_size_s=60,
    merge_vad=True,
    merge_length_s=15,
)

# å¤„ç†æ¯ä¸ªéŸ³é¢‘çš„è¯†åˆ«ç»“æœ
for i, res in enumerate(results):
    text = rich_transcription_postprocess(res["text"])
    emotion = text[-1]
    if emotion == "ğŸ˜Š":
        emotion = "å¼€å¿ƒ"
    elif emotion == "ğŸ˜”":
        emotion = "æ‚²ä¼¤" 
    elif emotion == "ğŸ˜¡":
        emotion = "æ„¤æ€’"
    elif emotion == "ğŸ˜°":
        emotion = "ææƒ§"
    elif emotion == "ğŸ¤¢":
        emotion = "åŒæ¶"
    elif emotion == "ğŸ˜®":
        emotion = "æƒŠè®¶"
    else:
        emotion = "ä¸­ç«‹"
    print(f"\néŸ³é¢‘ {i+1}:")
    print(f"è¯†åˆ«æ–‡æœ¬: {text}")
    print(f"æƒ…æ„ŸçŠ¶æ€: {emotion}")
